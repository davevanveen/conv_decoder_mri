{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sigpy\n",
    "from sigpy.mri.samp import poisson\n",
    "import torch\n",
    "from torch.fft import ifftn\n",
    "\n",
    "sys.path.append('/home/vanveen/ConvDecoder/')\n",
    "from utils.data_io import load_h5, load_output, save_output, \\\n",
    "                            expmt_already_generated\n",
    "from utils.transform import np_to_tt, split_complex_vals, recon_ksp_to_img, ifft_2d\n",
    "from utils.helpers import num_params, get_masks\n",
    "from include.decoder_conv import init_convdecoder\n",
    "from include.mri_helpers import data_consistency\n",
    "from include.fit import fit\n",
    "from utils.evaluate import calc_metrics\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    torch.cuda.set_device(1)\n",
    "    \n",
    "from utils.transform import np_to_tt, np_to_var, ifft_2d, fft_2d, root_sum_squares, \\\n",
    "                        reshape_complex_channels_to_sep_dimn, \\\n",
    "                        reshape_complex_channels_to_be_adj, \\\n",
    "                        split_complex_vals, recon_ksp_to_img, \\\n",
    "                        fftshift, ifftshift, is_complex, reshape_adj_channels_to_be_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def root_sum_squares(arr):\n",
    "#     ''' given 3d complex arr [nc,x,y], perform rss over magnitudes \n",
    "#         return 2d arr [x,y] '''\n",
    "    \n",
    "#     assert is_complex(arr)\n",
    "#     return torch.sqrt(torch.sum(torch.square(abs(arr)), axis=0))\n",
    "\n",
    "def plot_single(arr):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(arr.detach().numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "path = '/bmrNAS/people/arjun/data/qdess_knee_2020/files_recon_calib-16/'\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "files.sort()\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data format\n",
    "- 'kspace': Nx x Ny x Nz x # echos x # coils\n",
    "- 'maps': Nx x Ny x Nz x # coils x # maps\n",
    "- 'target': Nx x Ny x Nz x # echos x # maps\n",
    "\n",
    "take kspace, run on one echo. what to do w num coils? recon all, then rss at end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data, make mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 512, 160])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = files[0]\n",
    "f = h5py.File(path + fn, 'r')\n",
    "\n",
    "# ksp = torch.from_numpy(f['kspace'][()])\n",
    "# targ = torch.from_numpy(f['target'][()])\n",
    "ksp = torch.from_numpy(np.load('ksp_3d_samp.npy'))\n",
    "\n",
    "# get echo1, reshape to be (nc, kx, ky, kz)\n",
    "ksp_vol = ksp[:,:,:,0,:].permute(3,0,1,2)\n",
    "ksp_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 160])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask = poisson(img_shape=(512, 160), accel=4)\n",
    "# mask = abs(mask)\n",
    "# np.save('mask_3d.npy', mask)\n",
    "mask = torch.from_numpy(np.load('mask_3d.npy').astype('float32'))\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get central slice in kx of volumes\n",
    "because dd+ requires a 2d recon, and we're undersampling in ky, kz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_kx = ksp_vol.shape[1] // 2\n",
    "ksp_orig = ksp_vol[:, idx_kx, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize network\n",
    "\n",
    "network has same num_params as original network w lone difference of 32 = 2 * n_c output channels instead of 30. hence as written now, network is agnostic to number of pixels in a slice, e.g. 512x512 would have same num_params as 512x160 -- is this right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice_ksp (nc, x, y) in original. now slice_ksp (nc, y, z)\n",
    "# mask is mask2d is (x,y) in original. now (y,z)\n",
    "net, net_input, ksp_orig = init_convdecoder(ksp_orig, mask)\n",
    "\n",
    "# from utils.helpers import num_params\n",
    "# params = [p.shape for p in net.parameters()]\n",
    "# params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply mask\n",
    "currently a modified version of the function call `ksp_masked, img_masked = get_masked_measurements(vol_ksp, mask_)` which has a bunch of data shape conversion nonsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 512, 160]),\n",
       " torch.Size([16, 512, 160]),\n",
       " torch.Size([16, 512, 160]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ksp_masked = ksp_orig * mask\n",
    "ksp_masked = ksp_orig * mask\n",
    "img_masked = ifft_2d(ksp_masked)\n",
    "\n",
    "ksp_orig.shape, ksp_masked.shape, img_masked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: make new data format work for fastmri\n",
    "    \n",
    "### do all array processing in torch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want img_masked, ksp_masked to be complex tensors shape [nc,x,y]\n",
    "net, mse_wrt_ksp, mse_wrt_img = fit(\n",
    "        ksp_masked=ksp_masked, img_masked=img_masked,\n",
    "        net=net, net_input=net_input, mask2d=mask, num_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIX\n",
    "\n",
    "- something weird going on w the scaling\n",
    "- when i make ksp_dc with...\n",
    "    - ksp_orig (scaled by initcd()), output looks bad\n",
    "    - ksp_slice (not scaled), output looks decent\n",
    "- when i make ksp_est with...\n",
    "    - ksp_orig (scaled), output looks shit just like ksp_dc\n",
    "    - ksp_slice (not scaled), output looks decent... but still ksp_dc looks bad\n",
    "    \n",
    "    \n",
    "- img_dc looks the same whether or not img_est looks like crap or something sensible --> perhaps there is some bug with the ksp_dc step?\n",
    "- recon completely fails if ksp_orig isn't scaled\n",
    "    \n",
    "# big difference when using unscaled v scaled version of ksp for dc step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_slice = torch.from_numpy(np.load('ksp_slice_ie_nonscaled.npy'))\n",
    "abs(ksp_slice - ksp_orig).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = net(net_input.type(dtype))[0]\n",
    "\n",
    "# make complex tensor [nc,x,y] from [2*nc,x,y]\n",
    "img_out = reshape_adj_channels_to_be_complex(img_out)\n",
    "\n",
    "ksp_est = fft_2d(img_out)\n",
    "\n",
    "# apply dc step using 3d boolean mask\n",
    "mask_3d_bool = mask.expand(ksp_orig.shape).type(torch.bool)\n",
    "ksp_dc = torch.where(mask_3d_bool, ksp_orig, ksp_est) # arg 2 either ksp_slice (non-scaled) or ksp_orig (scaled)\n",
    "\n",
    "abs(ksp_slice).max(), abs(ksp_orig).max(), abs(ksp_est).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create images from k-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_est = root_sum_squares(ifft_2d(ksp_est))\n",
    "\n",
    "img_dc = root_sum_squares(ifft_2d(ksp_dc))\n",
    "\n",
    "img_gt = root_sum_squares(ifft_2d(ksp_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single(img_dc)\n",
    "plot_single(img_est)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
