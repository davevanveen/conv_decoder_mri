{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sigpy\n",
    "from sigpy.mri.samp import poisson\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/vanveen/ConvDecoder/')\n",
    "from utils.data_io import load_h5_qdess, num_params\n",
    "from include.decoder_conv import init_convdecoder\n",
    "from include.fit import fit\n",
    "from utils.evaluate import calc_metrics\n",
    "from utils.transform import fft_2d, ifft_2d, root_sum_squares, \\\n",
    "                            reshape_complex_vals_to_adj_channels, \\\n",
    "                            reshape_adj_channels_to_complex_vals\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCEL_LIST = [4] # 4, 6, 8]\n",
    "NUM_ITER = 1\n",
    "\n",
    "def run_expmt(file_id_list):\n",
    "\n",
    "    for file_id in file_id_list:\n",
    "\n",
    "#         t0 = time.time()\n",
    "#         ksp = load_h5_qdess(file_id)\n",
    "#         t1 = time.time()\n",
    "        \n",
    "#         # load, concat both echo slices\n",
    "#         idx_kx = ksp.shape[0] // 2 # want central slice in kx (axial) b/c we undersample in (ky,kz)\n",
    "#         ksp_echo1 = ksp[:,:,:,0,:].permute(3,0,1,2)[:, idx_kx, :, :]\n",
    "#         ksp_echo2 = ksp[:,:,:,1,:].permute(3,0,1,2)[:, idx_kx, :, :]\n",
    "#         ksp_orig = torch.cat((ksp_echo1, ksp_echo2), 0)\n",
    "        \n",
    "#         np.save('delete_me_ksp_orig_mtr_005.npy', np.array(ksp_orig))\n",
    "\n",
    "        ksp_orig = torch.from_numpy(np.load('delete_me_ksp_orig_mtr_005.npy'))\n",
    "\n",
    "        for ACCEL in ACCEL_LIST:\n",
    "\n",
    "            path_out = '/bmrNAS/people/dvv/out_qdess/accel_{}x/echo_joint/new_layers/'.format(ACCEL)\n",
    "            if os.path.exists('{}{}_e1-joint-recon_dc.npy'.format(path_out, file_id)):\n",
    "                continue\n",
    "\n",
    "            # original masks created w central region 32x32 forced to 1's\n",
    "            mask = torch.from_numpy(np.load('/home/vanveen/ConvDecoder/ipynb/masks/mask_poisson_disc_{}x.npy'.format(ACCEL)))\n",
    "\n",
    "            # initialize network\n",
    "            net, net_input, ksp_orig_ = init_convdecoder(ksp_orig, mask)\n",
    "\n",
    "            # apply mask after rescaling k-space. want complex tensors dim (nc, ky, kz)\n",
    "            ksp_masked = ksp_orig_ * mask\n",
    "            img_masked = ifft_2d(ksp_masked)\n",
    "\n",
    "            # fit network, get net output\n",
    "\n",
    "            net, mse_wrt_ksp, mse_wrt_img = fit(\n",
    "                ksp_masked=ksp_masked, img_masked=img_masked,\n",
    "                net=net, net_input=net_input, mask2d=mask, num_iter=NUM_ITER)\n",
    "            img_out = net(net_input.type(dtype)) # real tensor dim (2*nc, kx, ky)\n",
    "            img_out = reshape_adj_channels_to_complex_vals(img_out[0]) # complex tensor dim (nc, kx, ky)\n",
    "\n",
    "            # perform dc step\n",
    "            ksp_est = fft_2d(img_out)\n",
    "            ksp_dc = torch.where(mask, ksp_masked, ksp_est)\n",
    "        \n",
    "#         t2 = time.time()\n",
    "#         print(t1-t0)\n",
    "#         print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(ksp_masked, img_masked, net, net_input, mask2d,\n",
    "        mask1d=None, ksp_orig=None, DC_STEP=False, alpha=0.5,\n",
    "        num_iter=5000, lr=0.01, img_ls=None, dtype=torch.cuda.FloatTensor,\n",
    "        c_wmse=None, LOSS_IN_KSP=True):\n",
    "    \n",
    "    # initialize variables\n",
    "    if img_ls is not None or net_input is None:\n",
    "        raise NotImplementedError('incorporate original code here')\n",
    "    if alpha < 0 or alpha >= 1:\n",
    "        raise ValueError('alpha must be non-negative and strictly less than 1')\n",
    "    net_input = net_input.type(dtype)\n",
    "    best_net = copy.deepcopy(net)\n",
    "    best_mse = 10000.0\n",
    "    mse_wrt_ksp, mse_wrt_img = np.zeros(num_iter), np.zeros(num_iter)\n",
    "\n",
    "    p = [x for x in net.parameters()]\n",
    "    optimizer = torch.optim.Adam(p, lr=lr,weight_decay=0)\n",
    "    mse = torch.nn.MSELoss()\n",
    "\n",
    "    # convert complex [nc,x,y] --> real [2*nc,x,y] to match w net output\n",
    "    ksp_masked = reshape_complex_vals_to_adj_channels(ksp_masked).cuda()\n",
    "    img_masked = reshape_complex_vals_to_adj_channels(img_masked)[None,:].cuda()\n",
    "    mask2d = mask2d.cuda()\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        def closure(): # execute this for each iteration (gradient step)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = net(net_input) # out is in img space\n",
    "            print(out.shape)\n",
    "            \n",
    "            if LOSS_IN_KSP:\n",
    "                out_ksp_masked = forwardm(out, mask2d).cuda() # convert img to ksp, apply mask\n",
    "                loss_ksp = mse(out_ksp_masked, ksp_masked)\n",
    "                loss_ksp.backward(retain_graph=False)\n",
    "            else:\n",
    "                out_img_masked = forwardm_img(out, mask2d) # img-->ksp, apply mask, convert to img\n",
    "                loss_img = mse(out_img_masked, img_masked)\n",
    "                loss_img.backward(retain_graph=False)\n",
    "\n",
    "#             mse_wrt_ksp[i] = loss_ksp.data.cpu().numpy() # store loss over each iteration\n",
    "            if LOSS_IN_KSP:\n",
    "                return loss_ksp\n",
    "            else:\n",
    "                return loss_img\n",
    "\n",
    "        loss = optimizer.step(closure)\n",
    "\n",
    "        # at each iteration, check if loss improves by 1%. if so, a new best net\n",
    "        loss_val = loss.data\n",
    "        if best_mse > 1.005*loss_val:\n",
    "            best_mse = loss_val\n",
    "            best_net = copy.deepcopy(net)\n",
    "\n",
    "    return best_net, mse_wrt_ksp, mse_wrt_img\n",
    "\n",
    "def forwardm_img(img, mask):\n",
    "    ''' convert img --> ksp (must be complex for fft), apply mask\n",
    "        convert back to img. input dim [2*nc,x,y], output dim [1,2*nc,x,y] '''\n",
    "\n",
    "    img = reshape_adj_channels_to_complex_vals(img[0])\n",
    "    ksp = fft_2d(img).cuda()\n",
    "    ksp_masked_ = ksp * mask\n",
    "    img_masked_ = ifft_2d(ksp_masked_)\n",
    "    \n",
    "    return reshape_complex_vals_to_adj_channels(img_masked_)[None, :]\n",
    "\n",
    "def forwardm(img, mask):\n",
    "    ''' convert img --> ksp (must be complex for fft), apply mask\n",
    "        input, output should have dim [2*nc,x,y] '''\n",
    "\n",
    "    img = reshape_adj_channels_to_complex_vals(img[0])\n",
    "    ksp = fft_2d(img).cuda()\n",
    "    ksp_masked_ = ksp * mask\n",
    "\n",
    "    return reshape_complex_vals_to_adj_channels(ksp_masked_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- get baseline recon in im-space using l2. should be the same as k-space. verify this.\n",
    "- next, add tv reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 512, 160])\n"
     ]
    }
   ],
   "source": [
    "file_id_list = ['005']\n",
    "\n",
    "run_expmt(file_id_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
