{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Purpose\n",
    "\n",
    "Make the data consistency step differentiable in pytorch so it can be applied to the loss function during network fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.transform import np_to_tt, np_to_var, apply_mask, ifft_2d, fft_2d, \\\n",
    "                            reshape_complex_channels_to_sep_dimn, \\\n",
    "                            reshape_complex_channels_to_be_adj, \\\n",
    "                            split_complex_vals, combine_complex_channels, \\\n",
    "                            crop_center, root_sum_of_squares\n",
    "from utils.helpers import num_params, get_masks, load_h5\n",
    "from include.decoder_conv import convdecoder\n",
    "from include.mri_helpers import get_scale_factor\n",
    "from include.fit import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '1000267'\n",
    "f, slice_ksp = load_h5(file_id)\n",
    "\n",
    "\n",
    "# duplicated from other ipynb to get variables for testing purposes\n",
    "in_ksp = np_to_tt(reshape_complex_channels_to_be_adj(split_complex_vals(slice_ksp)))\n",
    "_, _, mask1d = get_masks(f, slice_ksp)\n",
    "img_out = in_ksp # same shape as net output for testing purposes -- actually ksp meas tho\n",
    "\n",
    "# pre-processing for new inputs into fit() -- added in main script\n",
    "ksp_orig = np_to_tt(split_complex_vals(slice_ksp)) # ([15, 640, 368, 2]); slice_ksp (15,640,368) complex\n",
    "mask1d = torch.from_numpy(np.array(mask1d, dtype=np.uint8)) # shape: torch.Size([368]) w 41 non-zero elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the following command differentiable, create a new function for use in `fit.py`\n",
    "\n",
    "`ksp_est[:,:,mask1d==1,:] = ksp_orig[:,:,mask1d==1,:]`\n",
    "\n",
    "##### SOLVED: implementation woes  in `data_consistency_iter()`\n",
    "- given ksp, ksp_orig, mask1d: \n",
    "    - (1) make a clone of ksp, called ksp_dc. can't use ksp directly, as this will break the differentiable chain\n",
    "    - (2) replace values of ksp_dc with those from ksp_orig according to indices determined by mask1d\n",
    "    - (3) interpolate b/w ksp and ksp_dc\n",
    "\n",
    "old notes:\n",
    "- if index_select doesn't work, think of other ways we can perform dc step using interpolation\n",
    "    - possible torch.nn.functional.grid_sample? see examples:\n",
    "        - https://pytorch.org/docs/stable/nn.functional.html\n",
    "        - https://discuss.pytorch.org/t/differentiable-indexing/17647/4\n",
    "        - https://www.programcreek.com/python/example/104458/torch.nn.functional.grid_sample\n",
    "\n",
    "\n",
    "##### outstanding questions\n",
    "- sampling may not produce a meaningful gradient --> perhaps use interpolation instead?\n",
    "    - interpolation example: https://discuss.pytorch.org/t/indexing-a-variable-with-a-variable/2111/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic interpolation examples -- works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp = img_out\n",
    "ksp_dc.shape\n",
    "\n",
    "from torch.autograd import Variable\n",
    "zz = Variable(torch.randn(ksp.shape), requires_grad=True)\n",
    "\n",
    "# linearly combine network output and ksp_orig (zz)\n",
    "alpha = 0.5 \n",
    "out = alpha*ksp + (1-alpha)*zz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using index_select -- fails as written\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.index_select.html\n",
    "\n",
    "in data_consistency_iter():\n",
    "\n",
    "#mask1d_idx = Variable(torch.LongTensor([1]*len(mask1d))).cuda()\n",
    "\n",
    "#return torch.index_select(ksp, 3, mask1d_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must convert mask1d into indices at which it contains 1's\n",
    "# e.g. mask1d=[0, 1, 1, 0] --> indices=torch.tensor([1, 2])\n",
    "# then, call torch.index_select(arr_ksp, 2, indices)\n",
    "\n",
    "mask1d_idx = Variable(torch.where(mask1d)[0])\n",
    "# mask1d_idx = Variable(torch.LongTensor([1]*len(mask1d)))\n",
    "\n",
    "arr_select = torch.index_select(arr_ksp, 2, mask1d_idx)\n",
    "print(arr_ksp.shape, arr_select.shape, len(mask1d_idx))\n",
    "\n",
    "###\n",
    "# template example\n",
    "x = Variable(torch.randn(3,3), requires_grad=True)\n",
    "print(x)\n",
    "idx = Variable(torch.LongTensor([0,2]))\n",
    "print(x.index_select(0, idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unused: functions converted from numpy to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_complex_channels_to_be_adj_tt(arr):\n",
    "    ''' (15,x,y,2) --> (30,x,y) '''\n",
    "\n",
    "    arr_out = torch.empty(2*arr.shape[0], arr.shape[1], arr.shape[2])\n",
    "    for idx, a in enumerate(arr):\n",
    "        arr_out[2*idx], arr_out[2*idx+1] = a[:,:,0], a[:,:,1]\n",
    "\n",
    "    return arr_out\n",
    "\n",
    "def combine_complex_channels_tt(arr):\n",
    "    ''' (30,x,y) --> (15,x,y) via combining real/complex vals into single magnitude '''\n",
    "\n",
    "    num_coils = int(arr.shape[0] / 2)\n",
    "    arr_out = torch.empty(num_coils, arr.shape[1], arr.shape[2])\n",
    "    for idx in range(num_coils):\n",
    "        arr_out[idx] = torch.sqrt(torch.square(arr[2*idx]) + torch.square(arr[2*idx+1]))\n",
    "    return arr_out\n",
    "\n",
    "def root_sum_of_squares_tt(arr):\n",
    "    ''' given 3D torch tensor e.g. 2D slices from multiple coils\n",
    "        combine each slice into a single 2D tensor via rss '''\n",
    "    return torch.sqrt(torch.sum(torch.square(arr), axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
