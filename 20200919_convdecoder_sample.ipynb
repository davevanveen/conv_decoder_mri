{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Purpose\n",
    "\n",
    "Demo a run of ConvDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from utils.transform import np_to_tt, np_to_var, apply_mask, ifft_2d, fft_2d, \\\n",
    "                            reshape_complex_channels_to_sep_dimn, \\\n",
    "                            reshape_complex_channels_to_be_adj, \\\n",
    "                            split_complex_vals, combine_complex_channels, \\\n",
    "                            crop_center, root_sum_of_squares, recon_ksp_to_img\n",
    "from utils.helpers import num_params, load_h5, get_masks\n",
    "from include.decoder_conv import convdecoder\n",
    "from include.mri_helpers import get_scale_factor\n",
    "from include.fit import fit\n",
    "\n",
    "from pytorch_msssim import ms_ssim\n",
    "from utils.evaluate import calc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_measurements(slice_ksp, mask):\n",
    "    ''' parameters: \n",
    "                slice_ksp: original, unmasked k-space measurements\n",
    "                mask: mask used to downsample original k-space\n",
    "        return:\n",
    "                ksp_masked: masked measurements to fit\n",
    "                img_masked: masked image, i.e. ifft(ksp_masked) '''\n",
    "\n",
    "    # mask the kspace\n",
    "    ksp_masked = apply_mask(np_to_tt(slice_ksp), mask=mask)\n",
    "    ksp_masked = np_to_var(ksp_masked.data.cpu().numpy()).type(dtype)\n",
    "\n",
    "    # perform ifft of masked kspace\n",
    "    img_masked = ifft_2d(ksp_masked[0]).cpu().numpy()\n",
    "    img_masked = reshape_complex_channels_to_be_adj(img_masked)\n",
    "    img_masked = np_to_var(img_masked).type(dtype)\n",
    "    \n",
    "    return ksp_masked, img_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_consistency(img_out, slice_ksp, mask1d):\n",
    "    ''' perform data-consistency step \n",
    "        parameters:\n",
    "                img_out: network output image, shape torch.Size([30, x, y])\n",
    "                slice_ksp: original k-space measurements \n",
    "        returns:\n",
    "                img_dc: data-consistent output image\n",
    "                img_est: output image without data consistency '''\n",
    "    \n",
    "    img_out = reshape_complex_channels_to_sep_dimn(img_out)\n",
    "\n",
    "    # now get F*G(\\hat{C}), i.e. estimated recon in k-space\n",
    "    ksp_est = fft_2d(img_out) # ([15, 640, 368, 2])\n",
    "    ksp_orig = np_to_tt(split_complex_vals(slice_ksp)) # ([15, 640, 368, 2]); slice_ksp (15,640,368) complex\n",
    "\n",
    "    # replace estimated coeffs in k-space by original coeffs if it has been sampled\n",
    "    mask1d = torch.from_numpy(np.array(mask1d, dtype=np.uint8)) # shape: torch.Size([368]) w 41 non-zero elements\n",
    "    ksp_dc = ksp_est.clone().detach().cpu()\n",
    "    ksp_dc[:,:,mask1d==1,:] = ksp_orig[:,:,mask1d==1,:]\n",
    "\n",
    "    img_dc = recon_ksp_to_img(ksp_dc)\n",
    "    img_est = recon_ksp_to_img(ksp_est.detach().cpu())\n",
    "    \n",
    "    return img_dc, img_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO for new ipynb\n",
    "- call load_h5() with full path instead of file_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load measurements y and mask M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_id 1000411 w ksp shape (num_slices, num_coils, x, y): (40, 15, 640, 368)\n"
     ]
    }
   ],
   "source": [
    "file_id = '1000411'\n",
    "filename = '/bmrNAS/people/dvv/multicoil_test_v2/file{}_v2.h5'.format(file_id)\n",
    "\n",
    "f, slice_ksp = load_h5(file_id)\n",
    "\n",
    "mask, mask2d, mask1d = get_masks(f, slice_ksp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ConvDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters of ConvDecoder: 1850560\n"
     ]
    }
   ],
   "source": [
    "in_size = [8,4]\n",
    "out_size = slice_ksp.shape[1:] # shape of (x,y) image slice, e.g. (640, 368)\n",
    "out_depth = slice_ksp.shape[0]*2 # 2*n_c, i.e. 2*15=30 if multi-coil\n",
    "num_layers = 8\n",
    "strides = [1]*(num_layers-1)\n",
    "num_channels = 160\n",
    "kernel_size = 3\n",
    "\n",
    "net = convdecoder(in_size, out_size, out_depth, num_layers, \\\n",
    "                  strides, num_channels).type(dtype)\n",
    "print('# parameters of ConvDecoder:',num_params(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous pre-processing / data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate network input\n",
    "# fix scaling b/w original image and network output\n",
    "scale_factor, net_input = get_scale_factor(net,\n",
    "                                   num_channels,\n",
    "                                   in_size,\n",
    "                                   slice_ksp)\n",
    "slice_ksp = slice_ksp * scale_factor\n",
    "\n",
    "# make torch versions for data consistency step in fit()\n",
    "mask1d_ = torch.from_numpy(np.array(mask1d, dtype=np.uint8)) \n",
    "ksp_orig = np_to_tt(split_complex_vals(slice_ksp)) # ([15, 640, 368, 2]); slice_ksp (15,640,368) complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR (createCuDNNHandle at /pytorch/aten/src/ATen/cudnn/Handle.cpp:9)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f0d0397f536 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x10a0c28 (0x7f0d04e7bc28 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #2: at::native::getCudnnHandle() + 0xe54 (0x7f0d04e7d404 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #3: <unknown function> + 0xf19f4c (0x7f0d04cf4f4c in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf1afe1 (0x7f0d04cf5fe1 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xf1f01b (0x7f0d04cfa01b in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f0d04cfa572 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #7: <unknown function> + 0xf86090 (0x7f0d04d61090 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #8: <unknown function> + 0xfca928 (0x7f0d04da5928 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f0d04cfbc0a in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #10: <unknown function> + 0xf863bb (0x7f0d04d613bb in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #11: <unknown function> + 0xfca984 (0x7f0d04da5984 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #12: <unknown function> + 0x2c80736 (0x7f0d3e511736 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: <unknown function> + 0x2ccff44 (0x7f0d3e560f44 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f0d3e129908 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: <unknown function> + 0x2d89705 (0x7f0d3e61a705 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f0d3e617a03 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f0d3e6187e2 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #18: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f0d3e610e59 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f0d4af54488 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #20: <unknown function> + 0xd6cb4 (0x7f0de808dcb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #21: <unknown function> + 0x9609 (0x7f0deaad4609 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #22: clone + 0x43 (0x7f0deac10103 in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-32b4a4452fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mksp_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_masked_measurements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_ksp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m net, mse_wrt_ksp, mse_wrt_img = fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mksp_masked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksp_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_masked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_masked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ConvDecoder/include/fit.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(ksp_masked, img_masked, net, net_input, mask2d, mask1d, ksp_orig, DC_STEP, num_iter, lr, img_ls, dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss_ksp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# at each iteration, check if loss improves by 1%. if so, a new best net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/heck/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/heck/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ConvDecoder/include/fit.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mloss_ksp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_ksp_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksp_masked\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loss w.r.t. masked k-space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# TODO: understand why we backprop on loss_ksp and not loss_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mloss_ksp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mmse_wrt_ksp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_ksp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/heck/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/heck/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR (createCuDNNHandle at /pytorch/aten/src/ATen/cudnn/Handle.cpp:9)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f0d0397f536 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x10a0c28 (0x7f0d04e7bc28 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #2: at::native::getCudnnHandle() + 0xe54 (0x7f0d04e7d404 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #3: <unknown function> + 0xf19f4c (0x7f0d04cf4f4c in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf1afe1 (0x7f0d04cf5fe1 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xf1f01b (0x7f0d04cfa01b in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f0d04cfa572 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #7: <unknown function> + 0xf86090 (0x7f0d04d61090 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #8: <unknown function> + 0xfca928 (0x7f0d04da5928 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f0d04cfbc0a in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #10: <unknown function> + 0xf863bb (0x7f0d04d613bb in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #11: <unknown function> + 0xfca984 (0x7f0d04da5984 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #12: <unknown function> + 0x2c80736 (0x7f0d3e511736 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: <unknown function> + 0x2ccff44 (0x7f0d3e560f44 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f0d3e129908 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: <unknown function> + 0x2d89705 (0x7f0d3e61a705 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f0d3e617a03 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f0d3e6187e2 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #18: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f0d3e610e59 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f0d4af54488 in /home/vanveen/heck/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #20: <unknown function> + 0xd6cb4 (0x7f0de808dcb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #21: <unknown function> + 0x9609 (0x7f0deaad4609 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #22: clone + 0x43 (0x7f0deac10103 in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "NUM_ITER = 1 # default 1000  \n",
    "\n",
    "ksp_masked, img_masked = get_masked_measurements(slice_ksp, mask)\n",
    "\n",
    "print(ksp_masked, img_masked, net_input)\n",
    "\n",
    "net, mse_wrt_ksp, mse_wrt_img = fit(\n",
    "    ksp_masked=ksp_masked, img_masked=img_masked,\n",
    "    net=net, net_input=net_input, mask2d=mask2d,\n",
    "    mask1d=mask1d_, ksp_orig=ksp_orig,\n",
    "    img_ls=None, num_iter=NUM_ITER, dtype=dtype)\n",
    "\n",
    "# estimate image \\hat{x} = G(\\hat{C})\n",
    "img_out = net(net_input.type(dtype))[0] \n",
    "\n",
    "# data consistency step\n",
    "img_dc, img_est = data_consistency(img_out, slice_ksp, mask1d)\n",
    "\n",
    "# create ground-truth from full k-space\n",
    "print('bug alert! ground-truth likely not computed properly')\n",
    "img_gt = recon_ksp_to_img(slice_ksp) # must do this after slice_ksp is scaled\n",
    "\n",
    "calc_metrics(img_dc, img_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, 2*len(file_id_list), 2):\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    ax1 = fig.add_subplot(141)\n",
    "    ax1.imshow(img_gt_list[i], cmap='gray')\n",
    "    ax1.set_title('ground-truth?')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2 = fig.add_subplot(142)\n",
    "    ax2.imshow(img_dc_list[i], cmap='gray')\n",
    "    ax2.set_title('conv_decoder, iter {}'.format(np.array(NUM_ITER_LIST).min()))\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3 = fig.add_subplot(143)\n",
    "    ax3.imshow(img_dc_list[i+1], cmap='gray')\n",
    "    ax3.set_title('conv_decoder')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax4 = fig.add_subplot(144)\n",
    "    ax4.imshow(img_est_list[i+1], cmap='gray')\n",
    "    ax4.set_title('conv_decoder w/o dc post')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
